{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_descriptions(filename, dataset):\n",
    "    file = open(filename, 'r')\n",
    "    doc = file.read()\n",
    "    file.close()\n",
    "    descriptions = dict()\n",
    "    for line in doc.split('\\n'):\n",
    "        tokens = line.split()\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        if image_id in dataset:\n",
    "            if image_id not in descriptions:\n",
    "                descriptions[image_id] = list()\n",
    "            desc = ' '.join(image_desc)\n",
    "            descriptions[image_id].append(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_names_filepath = '../../datasets/flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt'\n",
    "file = open(train_images_names_filepath, 'r')\n",
    "train_images_names = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "train_images = list()\n",
    "for line in train_images_names.split('\\n'):\n",
    "    if len(line) < 1:\n",
    "        continue\n",
    "    identifier = line.split('.')[0]\n",
    "    train_images.append(identifier)\n",
    "train_images_all = set(train_images)\n",
    "print('Dataset: %d' % len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: train=6000\n"
     ]
    }
   ],
   "source": [
    "train_descriptions = load_clean_descriptions('captions.txt', train_images_all)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_names_filepath = '../../datasets/flickr8k/Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "file = open(test_images_names_filepath, 'r')\n",
    "test_images_names = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "test_images = list()\n",
    "for line in test_images_names.split('\\n'):\n",
    "    if len(line) < 1:\n",
    "        continue\n",
    "    identifier = line.split('.')[0]\n",
    "    test_images.append(identifier)\n",
    "test_images_all = set(test_images)\n",
    "print('Dataset: %d' % len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: test=1000\n"
     ]
    }
   ],
   "source": [
    "test_descriptions = load_clean_descriptions('captions.txt', test_images_all)\n",
    "print('Descriptions: test=%d' % len(test_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7576"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocabulary = list()\n",
    "for key, value in train_descriptions.items():\n",
    "    for val in value:\n",
    "        caption = val.split()\n",
    "        for word in caption:\n",
    "            if word not in train_vocabulary:\n",
    "                 train_vocabulary.append(word)\n",
    "len(train_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3176"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vocabulary = list()\n",
    "for key, value in test_descriptions.items():\n",
    "    for val in value:\n",
    "        caption = val.split()\n",
    "        for word in caption:\n",
    "            if word not in test_vocabulary:\n",
    "                 test_vocabulary.append(word)\n",
    "len(test_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_vocabulary).issubset(train_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542\n"
     ]
    }
   ],
   "source": [
    "count_differences = 0\n",
    "for item in test_vocabulary:\n",
    "    if item not in train_vocabulary:\n",
    "        count_differences+=1\n",
    "print(count_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
